{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26427392it [00:06, 4319029.72it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 177898.38it/s]           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4423680it [00:00, 4716750.72it/s]                             \n",
      "8192it [00:00, 69604.85it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
