{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirillvladimirov/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/eli5/base_utils.py:28: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  init_args = inspect.getargspec(class_.__init__)\n",
      "/Users/kirillvladimirov/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/eli5/base_utils.py:36: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  return attr.s(class_, these=these, init=False, slots=True, **attrs_kwargs)  # type: ignore\n",
      "Using TensorFlow backend.\n",
      "/Users/kirillvladimirov/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/botocore/awsrequest.py:624: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  class HeadersDict(collections.MutableMapping):\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "# classifiaction \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "import catboost as ctb\n",
    "\n",
    "# for classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hp optimization imports\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import mlflow\n",
    "\n",
    "import re\n",
    "import eli5\n",
    "import gc\n",
    "import random    \n",
    "import math\n",
    "import psutil\n",
    "import pickle\n",
    "import datetime\n",
    "from time import time\n",
    "\n",
    "# save/load models\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n",
    "import timeit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../../data/raw/Gamma_Log_Facies_Type_Prediction/\"\n",
    "models_root = \"../../models/Gamma_Log_Facies_Type_Prediction/\"\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "pd.set_option('max_columns', 150)\n",
    "# rcParams['figure.figsize'] = 16,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "# Modified to support timestamp type, categorical type\n",
    "# Modified to add option to use float16 or not. feather format does not support float16.\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            # skip datetime type or categorical type\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.81 s, sys: 458 ms, total: 3.27 s\n",
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv(root + \"Train_File.csv\")\n",
    "test_df = pd.read_csv(root + \"Test_File.csv\")\n",
    "submit_df = pd.read_csv(root + \"Submission_File.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lags(df):\n",
    "    for i in range(0, 25):\n",
    "        df[\"lag_forward_{}\".format(i)] = df.GR.shift(i)\n",
    "        df[\"lag_backward_{}\".format(i)] = df.GR.shift(-i)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_ts = train_df[train_df[\"well_id\"] < 100]\n",
    "train_df_ts = train_df_ts.groupby(\"well_id\").apply(create_lags)\n",
    "train_df_ts = train_df_ts.fillna(0)\n",
    "\n",
    "valid_df_ts = train_df[train_df[\"well_id\"].isin(list(range(100,120)))]\n",
    "valid_df_ts = valid_df_ts.groupby(\"well_id\").apply(create_lags)\n",
    "valid_df_ts = valid_df_ts.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_df_ts.drop([\"label\"], axis=1), train_df_ts[\"label\"], \\\n",
    "            valid_df_ts.drop([\"label\"], axis=1), valid_df_ts[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22000, 53), (22000,), (5500, 53), (5500,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9012b164134dbcaff4ff05155b5401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=550, style=ProgressStyle(descriptâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #20 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #31 due to time out. Continuing to the next pipeline.\n",
      "Created new folder to save periodic pipeline: tpot_report\n",
      "Saving periodic pipeline from pareto front to tpot_report/pipeline_gen_1_idx_0_2019.12.05_10-58-24.py\n",
      "Saving periodic pipeline from pareto front to tpot_report/pipeline_gen_1_idx_1_2019.12.05_10-58-24.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _mate_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True.\n",
      "Invalid pipeline encountered. Skipping its evaluation.\n",
      "Invalid pipeline encountered. Skipping its evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Skipped pipeline #65 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #77 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #79 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #94 due to time out. Continuing to the next pipeline.\n",
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t0.8525583672189505\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.45, ExtraTreesClassifier__min_samples_leaf=7, ExtraTreesClassifier__min_samples_split=20, ExtraTreesClassifier__n_estimators=100)\n",
      "-2\t0.8626081372177977\tDecisionTreeClassifier(ExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=entropy, ExtraTreesClassifier__max_features=0.25, ExtraTreesClassifier__min_samples_leaf=2, ExtraTreesClassifier__min_samples_split=2, ExtraTreesClassifier__n_estimators=100), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=7, DecisionTreeClassifier__min_samples_leaf=3, DecisionTreeClassifier__min_samples_split=15)\n",
      "-3\t0.8641811594401899\tGradientBoostingClassifier(GaussianNB(ExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=1.0, ExtraTreesClassifier__min_samples_leaf=3, ExtraTreesClassifier__min_samples_split=9, ExtraTreesClassifier__n_estimators=100)), GradientBoostingClassifier__learning_rate=0.1, GradientBoostingClassifier__max_depth=3, GradientBoostingClassifier__max_features=0.35000000000000003, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=4, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=0.9500000000000001)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Saving periodic pipeline from pareto front to tpot_report/pipeline_gen_1_idx_2_2019.12.05_12-00-22.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Input contains NaN, infinity or a value too large for dtype('float32')..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 52.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=2 l1 was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 manhattan was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t0.8580704830463001\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=entropy, ExtraTreesClassifier__max_features=0.7500000000000001, ExtraTreesClassifier__min_samples_leaf=1, ExtraTreesClassifier__min_samples_split=18, ExtraTreesClassifier__n_estimators=100)\n",
      "-2\t0.8626081372177977\tDecisionTreeClassifier(ExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=True, ExtraTreesClassifier__criterion=entropy, ExtraTreesClassifier__max_features=0.25, ExtraTreesClassifier__min_samples_leaf=2, ExtraTreesClassifier__min_samples_split=2, ExtraTreesClassifier__n_estimators=100), DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=7, DecisionTreeClassifier__min_samples_leaf=3, DecisionTreeClassifier__min_samples_split=15)\n",
      "-3\t0.8658146585354762\tXGBClassifier(RandomForestClassifier(RobustScaler(input_matrix), RandomForestClassifier__bootstrap=True, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.15000000000000002, RandomForestClassifier__min_samples_leaf=7, RandomForestClassifier__min_samples_split=9, RandomForestClassifier__n_estimators=100), XGBClassifier__learning_rate=0.1, XGBClassifier__max_depth=1, XGBClassifier__min_child_weight=1, XGBClassifier__n_estimators=100, XGBClassifier__nthread=1, XGBClassifier__subsample=0.6500000000000001)\n",
      "\n",
      "Saving periodic pipeline from pareto front to tpot_report/pipeline_gen_2_idx_0_2019.12.05_12-20-47.py\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Saving periodic pipeline from pareto front to tpot_report/pipeline_gen_2_idx_2_2019.12.05_12-20-47.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "Skipped pipeline #173 due to time out. Continuing to the next pipeline.\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-1\t0.8580704830463001\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=entropy, ExtraTreesClassifier__max_features=0.7500000000000001, ExtraTreesClassifier__min_samples_leaf=1, ExtraTreesClassifier__min_samples_split=18, ExtraTreesClassifier__n_estimators=100)\n",
      "-2\t0.8679132587177594\tRandomForestClassifier(ExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=entropy, ExtraTreesClassifier__max_features=0.8, ExtraTreesClassifier__min_samples_leaf=15, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.2, RandomForestClassifier__min_samples_leaf=12, RandomForestClassifier__min_samples_split=8, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Saving periodic pipeline from pareto front to tpot_report/pipeline_gen_3_idx_1_2019.12.05_12-54-52.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 79.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "Skipped pipeline #214 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #246 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #248 due to time out. Continuing to the next pipeline.\n",
      "Generation 4 - Current Pareto front scores:\n",
      "-1\t0.8580704830463001\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=entropy, ExtraTreesClassifier__max_features=0.7500000000000001, ExtraTreesClassifier__min_samples_leaf=1, ExtraTreesClassifier__min_samples_split=18, ExtraTreesClassifier__n_estimators=100)\n",
      "-2\t0.87030022261145\tKNeighborsClassifier(StandardScaler(input_matrix), KNeighborsClassifier__n_neighbors=14, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Saving periodic pipeline from pareto front to tpot_report/pipeline_gen_4_idx_1_2019.12.05_13-21-37.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "Skipped pipeline #269 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #274 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #299 due to time out. Continuing to the next pipeline.\n",
      "Generation 5 - Current Pareto front scores:\n",
      "-1\t0.8580704830463001\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=entropy, ExtraTreesClassifier__max_features=0.7500000000000001, ExtraTreesClassifier__min_samples_leaf=1, ExtraTreesClassifier__min_samples_split=18, ExtraTreesClassifier__n_estimators=100)\n",
      "-2\t0.87030022261145\tKNeighborsClassifier(StandardScaler(input_matrix), KNeighborsClassifier__n_neighbors=14, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 61.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 65.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "Skipped pipeline #349 due to time out. Continuing to the next pipeline.\n",
      "Generation 6 - Current Pareto front scores:\n",
      "-1\t0.8580704830463001\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=entropy, ExtraTreesClassifier__max_features=0.7500000000000001, ExtraTreesClassifier__min_samples_leaf=1, ExtraTreesClassifier__min_samples_split=18, ExtraTreesClassifier__n_estimators=100)\n",
      "-2\t0.87030022261145\tKNeighborsClassifier(StandardScaler(input_matrix), KNeighborsClassifier__n_neighbors=14, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 cosine was provided as affinity. Ward can only work with euclidean distances..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 [14:23:58] src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?\n",
      "Stack trace:\n",
      "  [bt] (0) 1   libxgboost.dylib                    0x00000001247b4579 dmlc::LogMessageFatal::~LogMessageFatal() + 57\n",
      "  [bt] (1) 2   libxgboost.dylib                    0x00000001247b98b6 xgboost::LearnerImpl::LazyInitModel() + 806\n",
      "  [bt] (2) 3   libxgboost.dylib                    0x00000001247cf2fe XGBoosterUpdateOneIter + 158\n",
      "  [bt] (3) 4   _ctypes.cpython-37m-darwin.so       0x0000000107f223af ffi_call_unix64 + 79\n",
      "  [bt] (4) 5   ???                                 0x00007ffee9bf7700 0x0 + 140732820059904\n",
      "\n",
      ".\n",
      "Skipped pipeline #366 due to time out. Continuing to the next pipeline.\n",
      "Generation 7 - Current Pareto front scores:\n",
      "-1\t0.8580704830463001\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=entropy, ExtraTreesClassifier__max_features=0.7500000000000001, ExtraTreesClassifier__min_samples_leaf=1, ExtraTreesClassifier__min_samples_split=18, ExtraTreesClassifier__n_estimators=100)\n",
      "-2\t0.87030022261145\tKNeighborsClassifier(StandardScaler(input_matrix), KNeighborsClassifier__n_neighbors=14, KNeighborsClassifier__p=1, KNeighborsClassifier__weights=distance)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "Generation 8 - Current Pareto front scores:\n",
      "-1\t0.8597415213200117\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.7500000000000001, ExtraTreesClassifier__min_samples_leaf=4, ExtraTreesClassifier__min_samples_split=6, ExtraTreesClassifier__n_estimators=100)\n",
      "-2\t0.8706419346012501\tRandomForestClassifier(ExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.4, ExtraTreesClassifier__min_samples_leaf=3, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.25, RandomForestClassifier__min_samples_leaf=8, RandomForestClassifier__min_samples_split=11, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "Saving periodic pipeline from pareto front to tpot_report/pipeline_gen_8_idx_0_2019.12.05_15-04-41.py\n",
      "Saving periodic pipeline from pareto front to tpot_report/pipeline_gen_8_idx_1_2019.12.05_15-04-41.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 feature_names mismatch: ['row_id', 'well_id', 'GR', 'lag_forward_0', 'lag_backward_0', 'lag_forward_1', 'lag_backward_1', 'lag_forward_2', 'lag_backward_2', 'lag_forward_3', 'lag_backward_3', 'lag_forward_4', 'lag_backward_4', 'lag_forward_5', 'lag_backward_5', 'lag_forward_6', 'lag_backward_6', 'lag_forward_7', 'lag_backward_7', 'lag_forward_8', 'lag_backward_8', 'lag_forward_9', 'lag_backward_9', 'lag_forward_10', 'lag_backward_10', 'lag_forward_11', 'lag_backward_11', 'lag_forward_12', 'lag_backward_12', 'lag_forward_13', 'lag_backward_13', 'lag_forward_14', 'lag_backward_14', 'lag_forward_15', 'lag_backward_15', 'lag_forward_16', 'lag_backward_16', 'lag_forward_17', 'lag_backward_17', 'lag_forward_18', 'lag_backward_18', 'lag_forward_19', 'lag_backward_19', 'lag_forward_20', 'lag_backward_20', 'lag_forward_21', 'lag_backward_21', 'lag_forward_22', 'lag_backward_22', 'lag_forward_23', 'lag_backward_23', 'lag_forward_24', 'lag_backward_24'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52']\n",
      "expected lag_backward_1, GR, lag_forward_7, lag_backward_16, lag_forward_5, lag_backward_11, lag_backward_3, lag_forward_2, lag_backward_7, lag_forward_10, lag_forward_21, lag_backward_2, lag_backward_19, lag_backward_4, well_id, lag_backward_15, lag_forward_22, lag_forward_6, lag_forward_4, lag_forward_18, lag_forward_23, lag_forward_24, lag_forward_13, lag_backward_5, lag_backward_12, lag_forward_12, lag_backward_18, lag_forward_20, lag_forward_8, lag_backward_20, lag_forward_14, lag_backward_10, lag_backward_6, lag_backward_0, lag_forward_17, lag_forward_11, lag_backward_21, lag_backward_17, lag_forward_1, lag_backward_23, lag_forward_3, lag_backward_8, lag_backward_9, lag_backward_13, lag_backward_14, row_id, lag_forward_16, lag_backward_24, lag_forward_19, lag_forward_9, lag_forward_0, lag_backward_22, lag_forward_15 in input data\n",
      "training data did not have the following fields: f38, f17, f10, f0, f5, f51, f6, f50, f23, f4, f14, f36, f8, f13, f30, f18, f43, f12, f26, f42, f24, f28, f41, f48, f49, f20, f22, f29, f7, f11, f35, f44, f27, f19, f1, f31, f32, f37, f47, f16, f34, f21, f39, f2, f40, f25, f3, f33, f46, f15, f52, f45, f9.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True.\n",
      "Skipped pipeline #491 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #503 due to time out. Continuing to the next pipeline.\n",
      "Generation 9 - Current Pareto front scores:\n",
      "-1\t0.8597415213200117\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.7500000000000001, ExtraTreesClassifier__min_samples_leaf=4, ExtraTreesClassifier__min_samples_split=6, ExtraTreesClassifier__n_estimators=100)\n",
      "-2\t0.8706419346012501\tRandomForestClassifier(ExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.4, ExtraTreesClassifier__min_samples_leaf=3, ExtraTreesClassifier__min_samples_split=8, ExtraTreesClassifier__n_estimators=100), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.25, RandomForestClassifier__min_samples_leaf=8, RandomForestClassifier__min_samples_split=11, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "Generation 10 - Current Pareto front scores:\n",
      "-1\t0.8597415213200117\tExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.7500000000000001, ExtraTreesClassifier__min_samples_leaf=4, ExtraTreesClassifier__min_samples_split=6, ExtraTreesClassifier__n_estimators=100)\n",
      "-2\t0.8716139282013874\tRandomForestClassifier(ExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.4, ExtraTreesClassifier__min_samples_leaf=3, ExtraTreesClassifier__min_samples_split=10, ExtraTreesClassifier__n_estimators=100), RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=gini, RandomForestClassifier__max_features=0.25, RandomForestClassifier__min_samples_leaf=3, RandomForestClassifier__min_samples_split=11, RandomForestClassifier__n_estimators=100)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Saving periodic pipeline from pareto front to tpot_report/pipeline_gen_10_idx_1_2019.12.05_15-58-34.py\n",
      "\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tpot = TPOTClassifier(\n",
    "    generations=10, \n",
    "    population_size=50, \n",
    "    verbosity=3, \n",
    "    scoring=\"balanced_accuracy\",\n",
    "    periodic_checkpoint_folder=\"tpot_report\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE, \n",
    "    max_eval_time_mins=10,\n",
    ")\n",
    "\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "scores.append(tpot.score(X_test, y_test))\n",
    "tpot.export(f'tpot_exported_pipeline_{i}.py')\n",
    "print('Scores:', tpot.score(X_test, y_test))   \n",
    "print('Winning pipelines:', tpot.fitted_pipeline_)RANDOM_STATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from tpot.export_utils import set_param_recursive\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tpot.export_utils import set_param_recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 16s, sys: 9.56 s, total: 3min 26s\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "root = \"../../data/raw/Gamma_Log_Facies_Type_Prediction/\"\n",
    "\n",
    "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
    "train_df = pd.read_csv(root + \"Train_File.csv\")\n",
    "test_df = pd.read_csv(root + \"Test_File.csv\")\n",
    "submit_df = pd.read_csv(root + \"Submission_File.csv\")\n",
    "\n",
    "\n",
    "def create_lags(df):\n",
    "    for i in range(0, 25):\n",
    "        df[\"lag_forward_{}\".format(i)] = df.GR.shift(i)\n",
    "        df[\"lag_backward_{}\".format(i)] = df.GR.shift(-i)\n",
    "    return df\n",
    "\n",
    "\n",
    "train = train_df\n",
    "train = train.groupby(\"well_id\").apply(create_lags)\n",
    "train = train.fillna(0)\n",
    "\n",
    "test = test_df[[\"row_id\", \"well_id\", \"GR\"]]\n",
    "test = test.groupby(\"well_id\").apply(create_lags)\n",
    "test = test.fillna(0)\n",
    "\n",
    "X_train, y_train = train.drop(\"label\", axis=1), train[\"label\"]\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4400000, 53), (4400000,), (2200000, 53))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Average CV score on the training set was: 0.8716139282013874\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=ExtraTreesClassifier(\n",
    "        bootstrap=False, \n",
    "        criterion=\"gini\", \n",
    "        max_features=0.4, \n",
    "        min_samples_leaf=3, \n",
    "        min_samples_split=10, \n",
    "        n_estimators=500,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "    RandomForestClassifier(\n",
    "        bootstrap=False, \n",
    "        criterion=\"gini\", \n",
    "        max_features=0.25, \n",
    "        min_samples_leaf=3, \n",
    "        min_samples_split=11, \n",
    "        n_estimators=500,\n",
    "        n_jobs=-1\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "exported_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = models_root + \"tpot_pipeline.pkl\"\n",
    "dump(exported_pipeline, model_file)\n",
    "# loaded_model = load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = exported_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df[\"label\"] = results\n",
    "submit_df.to_csv(root+\"submission.csv\", index=False)\n",
    "submit_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ»Ð°ÑÑÐ¾Ð² Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ\n",
    "g = submit_df[\"label\"].value_counts()\n",
    "g = g.sort_index().T\n",
    "plt.bar(g.index, g.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .... (step 1 of 2) Processing standardscaler, total=   9.7s\n",
      "[Pipeline]  (step 2 of 2) Processing kneighborsclassifier, total= 1.2min\n",
      "CPU times: user 1min 16s, sys: 4.9 s, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('kneighborsclassifier',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=-1, n_neighbors=14, p=1,\n",
       "                                      weights='distance'))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Average CV score on the training set was: 0.87030022261145\n",
    "exported_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNeighborsClassifier(n_neighbors=14, p=1, weights=\"distance\", n_jobs=-1),\n",
    "    verbose=True,\n",
    ")\n",
    "# Fix random state for all the steps in exported pipeline\n",
    "set_param_recursive(exported_pipeline.steps, 'random_state', 42)\n",
    "\n",
    "\n",
    "exported_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 delayed_query(\n\u001b[1;32m    453\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 454\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m             )\n\u001b[1;32m    456\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = exported_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-72d20979b5a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmit_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msubmit_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"submission.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msubmit_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "submit_df[\"label\"] = results\n",
    "submit_df.to_csv(root+\"submission.csv\", index=False)\n",
    "submit_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÐºÐ»Ð°ÑÑÐ¾Ð² Ð´Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ\n",
    "g = submit_df[\"label\"].value_counts()\n",
    "g = g.sort_index().T\n",
    "plt.bar(g.index, g.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = models_root + \"tpot_knn_pipeline.pkl\"\n",
    "dump(exported_pipeline, model_file)\n",
    "# loaded_model = load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
