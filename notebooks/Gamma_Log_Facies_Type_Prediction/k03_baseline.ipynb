{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/kirillvladimirov/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/eli5/base_utils.py:28: DeprecationWarning: inspect.getargspec() is deprecated since Python 3.0, use inspect.signature() or inspect.getfullargspec()\n",
      "  init_args = inspect.getargspec(class_.__init__)\n",
      "/Users/kirillvladimirov/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/eli5/base_utils.py:36: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  return attr.s(class_, these=these, init=False, slots=True, **attrs_kwargs)  # type: ignore\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from albumentations import (\n",
    "    ToFloat, \n",
    "    CLAHE, \n",
    "    RandomRotate90, \n",
    "    Transpose, \n",
    "    ShiftScaleRotate, \n",
    "    Blur, \n",
    "    OpticalDistortion, \n",
    "    GridDistortion, \n",
    "    HueSaturationValue, \n",
    "    IAAAdditiveGaussianNoise, \n",
    "    GaussNoise, \n",
    "    MotionBlur, \n",
    "    MedianBlur, \n",
    "    IAAPiecewiseAffine, \n",
    "    IAASharpen, \n",
    "    IAAEmboss, \n",
    "    RandomContrast, \n",
    "    RandomBrightness, \n",
    "    Flip, \n",
    "    OneOf, \n",
    "    Compose\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import numbers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "# classifiaction \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "import catboost as ctb\n",
    "\n",
    "# for classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hp optimization imports\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import mlflow\n",
    "\n",
    "import re\n",
    "import eli5\n",
    "import gc\n",
    "import random    \n",
    "import math\n",
    "import psutil\n",
    "import pickle\n",
    "import datetime\n",
    "from time import time\n",
    "\n",
    "# save/load models\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n",
    "\n",
    "import numpy\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, train_test_split, GroupKFold, GroupShuffleSplit\n",
    "\n",
    "from numpy import zeros, newaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../../data/raw/Gamma_Log_Facies_Type_Prediction/\"\n",
    "models_root = \"../../models/Gamma_Log_Facies_Type_Prediction/\"\n",
    "submit_root = \"../../data/processed/Gamma_Log_Facies_Type_Prediction/\"\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "pd.set_option('max_columns', 150)\n",
    "# rcParams['figure.figsize'] = 16,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_count = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = models_root + f'k{exp_count}_baseline_best_model.h5'\n",
    "submit_file = submit_root + f'k{exp_count}_baseline_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(history, metric='mse'):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[f'val_{metric}'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.79 s, sys: 474 ms, total: 3.26 s\n",
      "Wall time: 3.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full_train_df = pd.read_csv(root + \"Train_File.csv\")\n",
    "full_test_df = pd.read_csv(root + \"Test_File.csv\")\n",
    "submit_df = pd.read_csv(root + \"Submission_File.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "full_train_df[[\"GR\"]] = scaler.fit_transform(full_train_df[[\"GR\"]])\n",
    "full_test_df[[\"GR\"]] = scaler.transform(full_test_df[[\"GR\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4400000, 4), (2200000, 4), (2200000, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df.shape, full_test_df.shape, submit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array([x.values[:,2:3].T for group, x in full_train_df.groupby('well_id')], dtype='float32')\n",
    "target = np.array([x.values[:,3:].T for group, x in full_train_df.groupby('well_id')], dtype='float32')\n",
    "test = np.array([x.values[:,3:4].T for group, x in full_test_df.groupby('well_id')], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 1, 1100), (4000, 1, 1100), (2000, 1, 1100))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, target.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.reshape(train.shape[0], train.shape[2])\n",
    "train_y = target.reshape(target.shape[0], target.shape[2])\n",
    "test_X = test.reshape(test.shape[0], test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 1100), (4000, 1100), (2000, 1100))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.astype(int)\n",
    "train_y_cat = to_categorical(train_y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X[:, :, newaxis]\n",
    "test_X = test_X[:, :, newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 1100, 1), (4000, 1100, 5), (2000, 1100, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y_cat.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv =     \n",
    "# public = \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(512, input_shape=(1100, 1), return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(TimeDistributed(Dense(5)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 80\n",
    "decay_rate = learning_rate / epochs\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint(model_file, monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "adam = Adam(learning_rate, decay=decay_rate)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/80\n",
      "1408/3200 [============>.................] - ETA: 7:44 - loss: 1.0898 - accuracy: 0.6089"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(train_X, train_y_cat, batch_size=128, epochs=epochs, validation_split=0.2, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = load_model(models_root+'k02_baseline_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_hat = model_1.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = np.argmax(y_hat.reshape((-1,5)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df[\"label\"] = predict\n",
    "submit_df.to_csv(submit_file, index=False)\n",
    "submit_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество классов для предсказания\n",
    "g = submit_df[\"label\"].value_counts()\n",
    "g = g.sort_index().T\n",
    "plt.bar(g.index, g.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
