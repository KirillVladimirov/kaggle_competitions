{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "# classifiaction \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "import catboost as ctb\n",
    "\n",
    "# for classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hp optimization imports\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import mlflow\n",
    "\n",
    "import eli5\n",
    "import gc\n",
    "import random    \n",
    "import math\n",
    "import psutil\n",
    "import pickle\n",
    "import datetime\n",
    "from time import time\n",
    "\n",
    "# save/load models\n",
    "from joblib import dump\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../../data/raw/Gamma_Log_Facies_Type_Prediction/\"\n",
    "models_root = \"../../models/Gamma_Log_Facies_Type_Prediction/\"\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "pd.set_option('max_columns', 150)\n",
    "# rcParams['figure.figsize'] = 16,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "# Modified to support timestamp type, categorical type\n",
    "# Modified to add option to use float16 or not. feather format does not support float16.\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            # skip datetime type or categorical type\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 134.28 MB\n",
      "Memory usage after optimization is: 29.37 MB\n",
      "Decreased by 78.1%\n",
      "Memory usage of dataframe is 67.14 MB\n",
      "Memory usage after optimization is: 117.77 MB\n",
      "Decreased by -75.4%\n",
      "CPU times: user 7.43 s, sys: 727 ms, total: 8.16 s\n",
      "Wall time: 8.23 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>well_id</th>\n",
       "      <th>GR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAX_0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>113.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAX_1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>120.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAX_2</td>\n",
       "      <td>2</td>\n",
       "      <td>5000</td>\n",
       "      <td>115.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAX_3</td>\n",
       "      <td>3</td>\n",
       "      <td>5000</td>\n",
       "      <td>118.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAX_4</td>\n",
       "      <td>4</td>\n",
       "      <td>5000</td>\n",
       "      <td>127.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199995</th>\n",
       "      <td>CAX_2199995</td>\n",
       "      <td>1095</td>\n",
       "      <td>6999</td>\n",
       "      <td>145.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199996</th>\n",
       "      <td>CAX_2199996</td>\n",
       "      <td>1096</td>\n",
       "      <td>6999</td>\n",
       "      <td>140.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199997</th>\n",
       "      <td>CAX_2199997</td>\n",
       "      <td>1097</td>\n",
       "      <td>6999</td>\n",
       "      <td>111.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199998</th>\n",
       "      <td>CAX_2199998</td>\n",
       "      <td>1098</td>\n",
       "      <td>6999</td>\n",
       "      <td>148.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199999</th>\n",
       "      <td>CAX_2199999</td>\n",
       "      <td>1099</td>\n",
       "      <td>6999</td>\n",
       "      <td>120.1875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           unique_id  row_id  well_id        GR\n",
       "0              CAX_0       0     5000  113.9375\n",
       "1              CAX_1       1     5000  120.8750\n",
       "2              CAX_2       2     5000  115.3125\n",
       "3              CAX_3       3     5000  118.8750\n",
       "4              CAX_4       4     5000  127.7500\n",
       "...              ...     ...      ...       ...\n",
       "2199995  CAX_2199995    1095     6999  145.3750\n",
       "2199996  CAX_2199996    1096     6999  140.8750\n",
       "2199997  CAX_2199997    1097     6999  111.2500\n",
       "2199998  CAX_2199998    1098     6999  148.8750\n",
       "2199999  CAX_2199999    1099     6999  120.1875\n",
       "\n",
       "[2200000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv(root + \"Train_File.csv\")\n",
    "test_df = pd.read_csv(root + \"Test_File.csv\")\n",
    "submit_df = pd.read_csv(root + \"Submission_File.csv\")\n",
    "\n",
    "reduce_mem_usage(train_df, use_float16=True);\n",
    "reduce_mem_usage(test_df, use_float16=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>well_id</th>\n",
       "      <th>GR</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112.8125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>123.5625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>111.6875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>123.6250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  well_id        GR  label\n",
       "0       0        0  143.5000      0\n",
       "1       1        0  112.8125      0\n",
       "2       2        0  123.5625      0\n",
       "3       3        0  111.6875      0\n",
       "4       4        0  123.6250      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>well_id</th>\n",
       "      <th>GR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAX_0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>113.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAX_1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>120.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAX_2</td>\n",
       "      <td>2</td>\n",
       "      <td>5000</td>\n",
       "      <td>115.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAX_3</td>\n",
       "      <td>3</td>\n",
       "      <td>5000</td>\n",
       "      <td>118.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAX_4</td>\n",
       "      <td>4</td>\n",
       "      <td>5000</td>\n",
       "      <td>127.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id  row_id  well_id        GR\n",
       "0     CAX_0       0     5000  113.9375\n",
       "1     CAX_1       1     5000  120.8750\n",
       "2     CAX_2       2     5000  115.3125\n",
       "3     CAX_3       3     5000  118.8750\n",
       "4     CAX_4       4     5000  127.7500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAX_0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAX_1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAX_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAX_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAX_4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id  label\n",
       "0     CAX_0    NaN\n",
       "1     CAX_1    NaN\n",
       "2     CAX_2    NaN\n",
       "3     CAX_3    NaN\n",
       "4     CAX_4    NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr = RandomForestClassifier(verbose=0)\n",
    "rfr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [50],\n",
    "    'max_depth' : [4, 8, 12],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  18 | elapsed:  5.6min remaining: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  18 | elapsed:  6.0min remaining: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  18 | elapsed:  6.0min remaining: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  18 | elapsed:  6.6min remaining: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  18 | elapsed:  6.7min remaining:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  18 | elapsed:  7.8min remaining:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  18 | elapsed:  8.3min remaining:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  18 | elapsed:  8.7min remaining:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  18 | elapsed: 10.9min remaining:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  18 | elapsed: 11.2min remaining:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  18 | elapsed: 11.3min remaining:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  18 | elapsed: 11.6min remaining:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  18 | elapsed: 13.3min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed: 13.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed: 13.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [4, 8, 12], 'n_estimators': [50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=50)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = train_df.drop(\"label\", axis=1), train_df[\"label\"]\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=False, random_state=RANDOM_STATE)\n",
    "model = GridSearchCV(\n",
    "    estimator=rfr, \n",
    "    param_grid=param_grid, \n",
    "    n_jobs=-1, cv=skf, \n",
    "    scoring=\"accuracy\", \n",
    "    verbose=50\n",
    ")\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47393772727272726"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 8, 'n_estimators': 50}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 16min 17s, sys: 1min 16s, total: 1h 17min 33s\n",
      "Wall time: 11min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=8, n_estimators=500, n_jobs=-1)\n",
    "rfc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 51s, sys: 7.82 s, total: 1min 59s\n",
      "Wall time: 21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_hat = rfc.predict(test_df[[\"row_id\", \"well_id\", \"GR\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df[\"label\"] = y_hat\n",
    "submit_df.to_csv(root+\"submission.csv\", index=False)\n",
    "submit_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAX_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAX_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAX_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAX_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAX_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CAX_5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAX_6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAX_7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CAX_8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAX_9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CAX_10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CAX_11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CAX_12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAX_13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CAX_14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CAX_15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CAX_16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CAX_17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CAX_18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CAX_19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id  label\n",
       "0      CAX_0      0\n",
       "1      CAX_1      0\n",
       "2      CAX_2      0\n",
       "3      CAX_3      0\n",
       "4      CAX_4      0\n",
       "5      CAX_5      0\n",
       "6      CAX_6      0\n",
       "7      CAX_7      0\n",
       "8      CAX_8      0\n",
       "9      CAX_9      0\n",
       "10    CAX_10      0\n",
       "11    CAX_11      0\n",
       "12    CAX_12      0\n",
       "13    CAX_13      0\n",
       "14    CAX_14      0\n",
       "15    CAX_15      0\n",
       "16    CAX_16      0\n",
       "17    CAX_17      0\n",
       "18    CAX_18      2\n",
       "19    CAX_19      2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAFQCAYAAADA9WbqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3df2zc9X348acdny8GZ7LS+UycoYx1IBY5ECkObbrJVjuBzz47LAmRSLxEU9tlzSrIELN6dX54WetBIpNkbUnYH1BpFqwNFGwSnW2qdU5GQ9vYQ2Rus0E9HA1M/GMxzWyIf3HfP/jmionDgn3F9vn5+Au/c58P78/rn3ve587ntHg8HkeSJM1r6TO9AUmSNPMMAkmSZBBIkiSDQJIkYRBIkiQgY6Y3MFPee+89hoaGCAQCpKWlzfR2JEn6jYvH44yOjnL99deTnj7xnsC8DYKhoSFeffXVmd6GJEmfuFtuuYVFixZNWJu3QRAIBID3h5KZmTnDu0mujo4OCgoKZnobKcWZJpfzTD5nmlypOs+RkRFeffXVxHPgB83bILj8NkFmZibBYHCGd5N8qXhNM82ZJpfzTD5nmlypPM/J3ir3Q4WSJMkgkCRJBoEkScIgkCRJGASSJAmDQJIkYRBIkiQMAkmShEEgSZIwCCRJEgaBJEnCIEiqkdHxmd4CAKtWrZrpLQCzZx6SpP/bvP3jRr8JmYEFVDzYONPbmDWOPXL3TG9BknSNvEMgSZIMAkmSdI1BMDg4SHl5OW+88caE9SeffJItW7Ykfu7u7qayspJwOMz27dsZGhoC4OLFi2zbto3S0lIqKyvp6+sDYGRkhKqqKkpLS1m3bh2dnZ0AxONx9u3bRzgcpqysjPb29sT/44knniAcDlNSUsILL7wwvauXJEnANQTBK6+8wqZNm+jq6pqw/stf/pJ/+Id/mLC2d+9eNm/eTHNzMwUFBRw+fBiAQ4cOUVhYSFNTExs3bqS2thaA+vp6srKyaGpqorq6mmg0CkBLSwudnZ3EYjEeffRRotEoY2NjnDlzhueff57Gxkaeeuop9u/fz9tvv52MOUiSNK/9n0Fw9OhRampqCIVCibWRkRH27NnDjh07Emujo6OcPn2akpISANavX09zczMAra2tVFRUAFBeXs7JkycZHR2ltbWVtWvXArB69WoGBgbo7u7mxIkTlJWVkZ6ezk033UR+fj4vv/wyJ0+e5M477yQYDPKpT32KO+64g9bW1qQNQ5Kk+er//C2Dy6/mP+iRRx5hw4YN/M7v/E5ibWBggOzsbDIy3j9lbm4uPT09APT29pKbm/v+/zAjg+zsbC5cuDBh/fIx58+fp7e3d0KAfHB9xYoVV6xPR0dHx7SO/6DZ8ut+s8kH3+6Z61LpWmYD55l8zjS55ts8P/avHf74xz/mrbfe4utf/zo//elPE+vxePyKx6alpV31POnpk9+cSE9Pn/RcH7U+HQUFBQSDwWmdQ1eXKpHU3t6eMtcyGzjP5HOmyZWq8xweHr7qC+GP/Wx6/PhxXnvtNe6++2527dpFR0cHf/VXf8XixYsZHBxkfPz9L6Pp6+tLvMoPhUL09/cDMDY2xuDgIDk5OYRCocQHDD94TF5e3sdalyRJ0/Oxg+Chhx6iqamJxsZGvvnNb1JQUMChQ4cIBAIUFhYSi8UAaGhooKioCIDi4mIaGhoAiMViFBYWEggEKC4uprHx/S/yaWtrIxgMkp+fT1FREceOHWN8fJxz587R1dXFihUrKCoq4oUXXuDdd9/lwoUL/OQnP2HNmjXJmoUkSfNWUr+psKamhmg0ypEjR1iyZAkHDhwAYMeOHUSjUSKRCIsWLaKurg6ALVu2sGfPHiKRCJmZmezfvx+AcDjMmTNnEh84rK2tZeHChdx2222sXbuWe+65h7GxMe6//37y8vKSeQmSJM1LafHJ3pifBy6/j5LszxD41cW/lkpfXZyq7yfOFOeZfM40uVJ1nh/13Oc3FUqSJINAkiQZBJIkCYNAkiRhEEiSJAwCSZKEQSBJkjAIJEkSBoEkScIgkCRJGASSJAmDQJIkYRBIkiQMAkmShEEgSZIwCCRJEgaBJEnCIJAkSRgEkiQJg0CSJGEQSJIkDAJJkoRBIEmSMAgkSRIGgSRJwiCQJEkYBJIkCYNAkiRhEEiSJAwCSZLExwiCwcFBysvLeeONNwD4/ve/T3l5ORUVFXz9619nZGQEgLNnz7JhwwZKSkrYuXMnY2NjAHR3d1NZWUk4HGb79u0MDQ0BcPHiRbZt20ZpaSmVlZX09fUBMDIyQlVVFaWlpaxbt47Ozk4A4vE4+/btIxwOU1ZWRnt7e/KmIUnSPHVNQfDKK6+wadMmurq6AHj99dd5/PHH+d73vsfzzz/Pe++9x1NPPQVAVVUVu3fvpqWlhXg8ztGjRwHYu3cvmzdvprm5mYKCAg4fPgzAoUOHKCwspKmpiY0bN1JbWwtAfX09WVlZNDU1UV1dTTQaBaClpYXOzk5isRiPPvoo0Wg0ER2SJGlqrikIjh49Sk1NDaFQCIDMzEz+5m/+huzsbNLS0rjlllvo7u7mzTff5NKlS6xcuRKA9evX09zczOjoKKdPn6akpGTCOkBraysVFRUAlJeXc/LkSUZHR2ltbWXt2rUArF69moGBAbq7uzlx4gRlZWWkp6dz0003kZ+fz8svv5zcqUiSNM9kXMuDLr9qv2zp0qUsXboUgAsXLvDkk0/y0EMP0dvbS25ubuJxubm59PT0MDAwQHZ2NhkZGRPWgQnHZGRkkJ2dzYULFyY91/nz5+nt7U2EyQfXJUnS1F1TEFxNT08PX/7yl9mwYQOf+cxn+Ld/+7crHpOWlkY8Hp90/WrS0ye/cZGenj7pua72+GvR0dEx5WM/bNWqVUk7V6pIpc94pNK1zAbOM/mcaXLNt3lOOQg6Ozv58z//c/70T/+UL37xiwDk5eXR39+feExfXx+hUIjFixczODjI+Pg4CxYsSKwDhEIh+vv7ueGGGxgbG2NwcJCcnBxCoRB9fX0sW7Zswrny8vISHzz84PpUFRQUEAwGp3y8PlqqRFJ7e3vKXMts4DyTz5kmV6rOc3h4+KovhKf00npwcJAvfelL7NixIxED8P5bCcFgMFFVDQ0NFBUVEQgEKCwsJBaLTVgHKC4upqGhAYBYLEZhYSGBQIDi4mIaGxsBaGtrIxgMkp+fT1FREceOHWN8fJxz587R1dXFihUrpnIZkiTp/5vSHYJnnnmG/v5+nnjiCZ544gkAvvCFL7Bjxw7q6urYtWsXQ0NDLF++nK1btwJQU1NDNBrlyJEjLFmyhAMHDgCwY8cOotEokUiERYsWUVdXB8CWLVvYs2cPkUiEzMxM9u/fD0A4HObMmTOJDxzW1taycOHC6U1BkqR5Li0+2Zvy88Dl2ybJfsug4sHGpJ1rrjv2yN0zvYWkSdXbhzPFeSafM02uVJ3nRz33+U2FkiTJIJAkSQaBJEnCIJAkSRgEkiQJg0CSJGEQSJIkDAJJkoRBIEmSMAgkSRIGgSRJwiCQJEkYBJIkCYNAkiRhEEiSJAwCSZKEQSBJkjAIJEkSBoEkScIgkCRJGASSJAmDQJIkYRBIkiQMAkmShEEgSZIwCCRJEgaBJEnCIJAkSRgEkiQJg0CSJGEQSJIkPkYQDA4OUl5ezhtvvAHAqVOnqKio4K677uLgwYOJx509e5YNGzZQUlLCzp07GRsbA6C7u5vKykrC4TDbt29naGgIgIsXL7Jt2zZKS0uprKykr68PgJGREaqqqigtLWXdunV0dnYCEI/H2bdvH+FwmLKyMtrb25MzCUmS5rFrCoJXXnmFTZs20dXVBcClS5eorq7m8OHDxGIxOjo6OHHiBABVVVXs3r2blpYW4vE4R48eBWDv3r1s3ryZ5uZmCgoKOHz4MACHDh2isLCQpqYmNm7cSG1tLQD19fVkZWXR1NREdXU10WgUgJaWFjo7O4nFYjz66KNEo9FEdEiSpKm5piA4evQoNTU1hEIhAM6cOcOyZcu48cYbycjIoKKigubmZt58800uXbrEypUrAVi/fj3Nzc2Mjo5y+vRpSkpKJqwDtLa2UlFRAUB5eTknT55kdHSU1tZW1q5dC8Dq1asZGBigu7ubEydOUFZWRnp6OjfddBP5+fm8/PLLyZ2KJEnzTMa1POjyq/bLent7yc3NTfwcCoXo6em5Yj03N5eenh4GBgbIzs4mIyNjwvqHz5WRkUF2djYXLlyY9Fznz5+nt7c3ESYfXJckSVN3TUHwYfF4/Iq1tLS0j71+Nenpk9+4SE9Pn/RcV3v8tejo6JjysR+2atWqpJ0rVaTSZzxS6VpmA+eZfM40uebbPKcUBHl5efT39yd+vvyq/cPrfX19hEIhFi9ezODgIOPj4yxYsCCxDu/fXejv7+eGG25gbGyMwcFBcnJyCIVC9PX1sWzZsgnnysvLS3zw8IPrU1VQUEAwGJzy8fpoqRJJ7e3tKXMts4HzTD5nmlypOs/h4eGrvhCe0kvr22+/nddff51z584xPj7O8ePHKSoqYunSpQSDwURVNTQ0UFRURCAQoLCwkFgsNmEdoLi4mIaGBgBisRiFhYUEAgGKi4tpbGwEoK2tjWAwSH5+PkVFRRw7dozx8XHOnTtHV1cXK1asmMplSJKk/29KdwiCwSAPP/ww9913H8PDwxQXFxMOhwGoq6tj165dDA0NsXz5crZu3QpATU0N0WiUI0eOsGTJEg4cOADAjh07iEajRCIRFi1aRF1dHQBbtmxhz549RCIRMjMz2b9/PwDhcJgzZ84kPnBYW1vLwoULpzcFSZLmubT4ZG/KzwOXb5sk+y2Digcbk3auue7YI3fP9BaSJlVvH84U55l8zjS5UnWeH/Xc5zcVSpIkg0CSJBkEkiQJg0CSJGEQSJIkDAJJkoRBIEmSMAgkSRIGgSRJwiCQJEkYBJIkCYNAkiRhEEiSJAwCSZKEQSBJkjAIJEkSBoEkScIgkCRJGASSJAmDQJIkYRBIkiQMAkmShEEgSZIwCCRJEgaBJEnCIJAkSRgEkiQJg0CSJGEQSJIkDAJJkoRBIEmSmGYQNDY2EolEiEQi7Nu3D4CzZ8+yYcMGSkpK2LlzJ2NjYwB0d3dTWVlJOBxm+/btDA0NAXDx4kW2bdtGaWkplZWV9PX1ATAyMkJVVRWlpaWsW7eOzs5OAOLxOPv27SMcDlNWVkZ7e/t0LkGSJDGNIHj33Xepra2lvr6exsZG2traOHXqFFVVVezevZuWlhbi8ThHjx4FYO/evWzevJnm5mYKCgo4fPgwAIcOHaKwsJCmpiY2btxIbW0tAPX19WRlZdHU1ER1dTXRaBSAlpYWOjs7icViPProo0Sj0UR0SJKkqZlyEIyPj/Pee+/x7rvvMjY2xtjYGBkZGVy6dImVK1cCsH79epqbmxkdHeX06dOUlJRMWAdobW2loqICgPLyck6ePMno6Citra2sXbsWgNWrVzMwMEB3dzcnTpygrKyM9PR0brrpJvLz83n55ZenNQRJkua7jKkemJ2dzY4dOygtLWXhwoXccccdBAIBcnNzE4/Jzc2lp6eHgYEBsrOzycjImLAO0NvbmzgmIyOD7OxsLly4MGH98jHnz5+nt7eXUCh0xfpUdXR0TPnYD1u1alXSzpUqUuktnVS6ltnAeSafM02u+TbPKQfBf/zHf/CDH/yAf/mXf2HRokX89V//NT/+8Y+veFxaWhrxeHzS9atJT5/8xkV6evqk57ra469FQUEBwWBwysfro6VKJLW3t6fMtcwGzjP5nGlypeo8h4eHr/pCeMrPpC+++CJr1qzhU5/6FJmZmaxfv56f/vSn9Pf3Jx7T19dHKBRi8eLFDA4OMj4+PmEdIBQKJY4ZGxtjcHCQnJwcQqFQ4gOGHzwmLy9v0nVJkjR1Uw6CW2+9lVOnTvHOO+8Qj8f50Y9+xB133EEwGEzcZmloaKCoqIhAIEBhYSGxWGzCOkBxcTENDQ0AxGIxCgsLCQQCFBcX09jYCEBbWxvBYJD8/HyKioo4duwY4+PjnDt3jq6uLlasWDGtIUiSNN9N+S2DP/qjP+IXv/gF69evJxAIsGLFCrZt28add97Jrl27GBoaYvny5WzduhWAmpoaotEoR44cYcmSJRw4cACAHTt2EI1GiUQiLFq0iLq6OgC2bNnCnj17iEQiZGZmsn//fgDC4TBnzpxJfOCwtraWhQsXTmsIkiTNd2nxyd6Unwcuv4+S7M8QVDzYmLRzzXXHHrl7preQNKn6fuJMcZ7J50yTK1Xn+VHPfX5ToSRJMggkSZJBIEmSMAgkSRIGgSRJwiCQJEkYBJIkCYNAkiRhEEiSJAwCSZKEQSBJkjAIJEkSBoEkScIgkCRJGASSJAmDQJIkYRBIkiQMAkmShEEgSZIwCCRJEgaBJEnCIJAkSRgEkiQJg0CSJGEQSJIkDAJJkoRBIEmSMAgkSRIGgSRJwiCQJElMMwh+9KMfsX79esLhMN/85jcBOHXqFBUVFdx1110cPHgw8dizZ8+yYcMGSkpK2LlzJ2NjYwB0d3dTWVlJOBxm+/btDA0NAXDx4kW2bdtGaWkplZWV9PX1ATAyMkJVVRWlpaWsW7eOzs7O6VyCJEliGkHw3//939TU1HD48GGOHTvGL37xC06cOEF1dTWHDx8mFovR0dHBiRMnAKiqqmL37t20tLQQj8c5evQoAHv37mXz5s00NzdTUFDA4cOHATh06BCFhYU0NTWxceNGamtrAaivrycrK4umpiaqq6uJRqPTnYEkSfPelIPghz/8IWVlZdxwww0EAgEOHjxIVlYWy5Yt48YbbyQjI4OKigqam5t58803uXTpEitXrgRg/fr1NDc3Mzo6yunTpykpKZmwDtDa2kpFRQUA5eXlnDx5ktHRUVpbW1m7di0Aq1evZmBggO7u7mkNQZKk+S5jqgeeO3eOQCDAl770Jfr6+vj85z/PzTffTG5ubuIxoVCInp4eent7J6zn5ubS09PDwMAA2dnZZGRkTFgHJhyTkZFBdnY2Fy5cmPRc58+fJz8/f6qXIknSvDflIBgfH6etrY36+nquu+46/vIv/5KsrKwrHpeWlkY8Hv9Y61eTnj75DY2rrV+Ljo6OKR/7YatWrUrauVJFe3v7TG8haVLpWmYD55l8zjS55ts8pxwEv/3bv82aNWtYvHgxAH/8x39Mc3MzCxYsSDymt7eXUChEXl4e/f39ifW+vj5CoRCLFy9mcHCQ8fFxFixYkFiH9+8u9Pf3c8MNNzA2Nsbg4CA5OTmEQiH6+vpYtmzZhHNNVUFBAcFgcMrH66OlSiS1t7enzLXMBs4z+ZxpcqXqPIeHh6/6QnjKL60///nP8+KLL3Lx4kXGx8f513/9V8LhMK+//jrnzp1jfHyc48ePU1RUxNKlSwkGg4naamhooKioiEAgQGFhIbFYbMI6QHFxMQ0NDQDEYjEKCwsJBAIUFxfT2NgIQFtbG8Fg0LcLJEmapinfIbj99tv58pe/zObNmxkdHeUP//AP2bRpE7/3e7/Hfffdx/DwMMXFxYTDYQDq6urYtWsXQ0NDLF++nK1btwJQU1NDNBrlyJEjLFmyhAMHDgCwY8cOotEokUiERYsWUVdXB8CWLVvYs2cPkUiEzMxM9u/fP90ZSJI07005CADuuece7rnnnglra9as4fnnn7/isbfeeivPPPPMFetLly6lvr7+ivWcnBwee+yxK9aDwSD79u2bxq4lSdKH+U2FkiTJIJAkSQaBJEnCIJAkSRgEkiQJg0CSJGEQSJIkDAJJkoRBIEmSMAgkSRIGgSRJwiCQJEkYBJIkCYNAkiRhEEiSJAwCSZKEQSBJkjAIJEkSBoEkScIgkCRJGASSJAmDQJIkYRBIkiQMAkmShEEgSZIwCCRJEgaBJEnCIJAkSRgEmuVGRsdnegsArFq1aqa3AMyeeUhKPRkzvQHpo2QGFlDxYONMb2PWOPbI3TO9BUkpyjsEkiQpOUGwb98+otEoAGfPnmXDhg2UlJSwc+dOxsbGAOju7qayspJwOMz27dsZGhoC4OLFi2zbto3S0lIqKyvp6+sDYGRkhKqqKkpLS1m3bh2dnZ0AxONx9u3bRzgcpqysjPb29mRcgiRJ89q0g+Cll17iueeeS/xcVVXF7t27aWlpIR6Pc/ToUQD27t3L5s2baW5upqCggMOHDwNw6NAhCgsLaWpqYuPGjdTW1gJQX19PVlYWTU1NVFdXJ4KjpaWFzs5OYrEYjz76KNFoNBEdkiRpaqYVBG+//TYHDx7kK1/5CgBvvvkmly5dYuXKlQCsX7+e5uZmRkdHOX36NCUlJRPWAVpbW6moqACgvLyckydPMjo6SmtrK2vXrgVg9erVDAwM0N3dzYkTJygrKyM9PZ2bbrqJ/Px8Xn755elchiRJ8960gmDPnj088MAD/NZv/RYAvb295ObmJv49NzeXnp4eBgYGyM7OJiMjY8L6h4/JyMggOzubCxcuTHqu8+fP09vbSygUumJdkiRN3ZR/y+Dpp59myZIlrFmzhmeffRZ4//39D0tLS7vq+tWkp0/eKenp6ZOe62qPvxYdHR1TPvbDZsuvps0m0/2MhzO9Uqp8biZVrmM2cabJNd/mOeUgiMVi9PX1cffdd/OrX/2Kd955h7S0NPr7+xOP6evrIxQKsXjxYgYHBxkfH2fBggWJdYBQKER/fz833HADY2NjDA4OkpOTQygUoq+vj2XLlk04V15eXuKDhx9cn6qCggKCweCUj9dH8wk9+VJhpu3t7SlxHbOJM02uVJ3n8PDwVV8IT/ml9Xe/+12OHz9OY2Mj999/P1/4whd46KGHCAaDiapqaGigqKiIQCBAYWEhsVhswjpAcXExDQ0NwPuRUVhYSCAQoLi4mMbG93//vK2tjWAwSH5+PkVFRRw7dozx8XHOnTtHV1cXK1asmOplSJIkfgNfTFRXV8euXbsYGhpi+fLlbN26FYCamhqi0ShHjhxhyZIlHDhwAIAdO3YQjUaJRCIsWrSIuro6ALZs2cKePXuIRCJkZmayf/9+AMLhMGfOnEl84LC2tpaFCxcm+zIkSZpX0uKTvSk/D1y+bZLstwz8Vr1fS9a36jnTX0uVbypM1duxM8mZJleqzvOjnvv8pkJJkmQQSJIkg0CSJGEQSJIkDAJJkoRBIEmSMAgkSRIGgSRJwiCQJEkYBJIkCYNAkiRhEEiSJAwCSZKEQSBJkjAIJEkSBoEkScIgkCRJGASSJAmDQJIkYRBIkiQMAkmShEEgSZIwCCRJEgaBJEnCIJAkSRgEkiQJg0CSJGEQSJIkDAJJkoRBIEmSMAgkSRLTDILvfOc7RCIRIpEI+/fvB+DUqVNUVFRw1113cfDgwcRjz549y4YNGygpKWHnzp2MjY0B0N3dTWVlJeFwmO3btzM0NATAxYsX2bZtG6WlpVRWVtLX1wfAyMgIVVVVlJaWsm7dOjo7O6dzCZIkiWkEwalTp3jxxRd57rnnaGho4Oc//znHjx+nurqaw4cPE4vF6Ojo4MSJEwBUVVWxe/duWlpaiMfjHD16FIC9e/eyefNmmpubKSgo4PDhwwAcOnSIwsJCmpqa2LhxI7W1tQDU19eTlZVFU1MT1dXVRKPR6c5AkqR5b8pBkJubSzQaJTMzk0AgwKc//Wm6urpYtmwZN954IxkZGVRUVNDc3Mybb77JpUuXWLlyJQDr16+nubmZ0dFRTp8+TUlJyYR1gNbWVioqKgAoLy/n5MmTjI6O0traytq1awFYvXo1AwMDdHd3T2sIkiTNdxlTPfDmm29O/HdXVxexWIwtW7aQm5ubWA+FQvT09NDb2zthPTc3l56eHgYGBsjOziYjI2PCOjDhmIyMDLKzs7lw4cKk5zp//jz5+flTuo6Ojo4pHTeZVatWJe1cqaK9vX1axzvTK013prNFqlzHbOJMk2u+zXPKQXDZa6+9xl/8xV/wta99jYyMDF5//fUJ/56WlkY8Hr/iuI9av5r09MlvaFxt/VoUFBQQDAanfLw+mk/oyZcKM21vb0+J65hNnGlypeo8h4eHr/pCeFofKmxvb+fP/uzPePDBB1m3bh15eXn09/cn/r23t5dQKHTFel9fH6FQiMWLFzM4OMj4+PiEdXj/7sLlY8bGxhgcHCQnJ4dQKJT4gOGHj5EkSVMz5SB46623+OpXv0pdXR2RSASA22+/nddff51z584xPj7O8ePHKSoqYunSpQSDwcTtl4aGBoqKiggEAhQWFhKLxSasAxQXF9PQ0ABALBajsLCQQCBAcXExjY2NALS1tREMBqf8doEkSXrflN8yePzxxxkeHubhhx9OrN177708/PDD3HfffQwPD1NcXEw4HAagrq6OXbt2MTQ0xPLly9m6dSsANTU1RKNRjhw5wpIlSzhw4AAAO3bsIBqNEolEWLRoEXV1dQBs2bKFPXv2EIlEyMzMTPy6oyRJmropB8GuXbvYtWvXpP/2/PPPX7F266238swzz1yxvnTpUurr669Yz8nJ4bHHHrtiPRgMsm/fvinsWJIkXY3fVChJkgwCSZJkEEjzzsjo+ExvYdb8OtdsmIU0W0z7ewgkzS2ZgQVUPNg409uYFY49cvdMb0GaNbxDIEmSDAJJkmQQSJIkDAJJkoRBIEmSMAgkSRIGgSRJwiCQpGmZLV9u5Jc9abr8YiJJmga/6Gkiv+xp7vIOgSRJMggkSZJBIEmSMAgkSRIGgSRJwiCQJEkYBJIkCYNAkiRhEEiSJAwCSZKEQSBJmmVmw99DmI9/G8K/ZSBJmlX8+xC/9kn+bQjvEEiSJINAkiQZBJIkCYNAkiRhEEiSJOZwEBw7doyysjLuvPNOnnzyyZnejiRJc9qc/LXDnp4eDh48yLPPPktmZib33nsvn/nMZ/j93//9md6aJElz0py8Q3Dq1Ck++9nPkpOTw3XXXUdJSQnNzc0zvS1JkuasOXmHoLe3l9zc3MTPoVCIM2fOfKxzxONxAEZGRpK6t5zrFyT1fHPZ8PBwUs7jTH/NmSaX80w+Z5pcyZrnZZef8y4/B35QWnyy1Vnuscce49133+WBBx4A4Omnn+bf//3f+du//djMqegAAAPuSURBVNtrPsf//u//8uqrr/6mtihJ0qx1yy23sGjRoglrc/IOQV5eHm1tbYmfe3t7CYVCH+sc119/PbfccguBQIC0tLRkb1GSpFknHo8zOjrK9ddff8W/zckg+NznPse3v/1tLly4QFZWFi+88ALf+MY3PtY50tPTr6gjSZJS3cKFCyddn5NBkJeXxwMPPMDWrVsZHR3lnnvu4bbbbpvpbUmSNGfNyc8QSJKk5JqTv3YoSZKSyyCQJEkGgSRJMggkSRIGgSRJwiCQJEkYBJIkCYNAkiRhEKScY8eOUVZWxp133smTTz4509tJCYODg5SXl/PGG2/M9FZSwne+8x0ikQiRSIT9+/fP9HbmvL//+7+nrKyMSCTCd7/73ZneTkrZt28f0Wh0prfxiTEIUkhPTw8HDx7kqaeeorGxke9///v88pe/nOltzWmvvPIKmzZtoqura6a3khJOnTrFiy++yHPPPUdDQwM///nP+eEPfzjT25qzfvazn/GTn/yE559/nh/84AfU19fzX//1XzO9rZTw0ksv8dxzz830Nj5RBkEKOXXqFJ/97GfJycnhuuuuo6SkhObm5pne1px29OhRampqPvZf09TkcnNziUajZGZmEggE+PSnP013d/dMb2vOuuOOO/jHf/xHMjIy+J//+R/Gx8e57rrrZnpbc97bb7/NwYMH+cpXvjLTW/lEzck/bqTJ9fb2kpubm/g5FApx5syZGdzR3FdbWzvTW0gpN998c+K/u7q6iMVifO9735vBHc19gUCAb33rWzzxxBOEw2Hy8vJmektz3p49e3jggQd46623ZnornyjvEKSQyf5OVVpa2gzsRPpor732Gl/84hf52te+xu/+7u/O9HbmvPvvv5+XXnqJt956i6NHj870dua0p59+miVLlrBmzZqZ3sonzjsEKSQvL4+2trbEz729vd7q1qzT3t7O/fffT3V1NZFIZKa3M6d1dnYyMjLCH/zBH5CVlcVdd93Ff/7nf870tua0WCxGX18fd999N7/61a945513+Lu/+zuqq6tnemu/cQZBCvnc5z7Ht7/9bS5cuEBWVhYvvPAC3/jGN2Z6W1LCW2+9xVe/+lUOHjw4L1+BJdsbb7zBt771Lf7pn/4JgH/+539mw4YNM7yrue2Dv6nx7LPP8rOf/WxexAAYBCklLy+PBx54gK1btzI6Oso999zDbbfdNtPbkhIef/xxhoeHefjhhxNr9957L5s2bZrBXc1dxcXFvPLKK/zJn/wJCxYs4K677vKui6YsLT7ZG8+SJGle8UOFkiTJIJAkSQaBJEnCIJAkSRgEkiQJg0CSJGEQSJIkDAJJkgT8P9uOY1K1ooWFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Количество классов для предсказания\n",
    "\n",
    "g = submit_df[\"label\"].value_counts()\n",
    "g = g.sort_index().T\n",
    "plt.bar(g.index, g.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Experiment 'gamma_log_facies_type_xgboost_cls_hyperopt' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-ea50fd972861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tracking_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mEXPERIMENT_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gamma_log_facies_type_xgboost_cls_hyperopt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/mlflow/tracking/fluent.py\u001b[0m in \u001b[0;36mcreate_experiment\u001b[0;34m(name, artifact_location)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInteger\u001b[0m \u001b[0mID\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \"\"\"\n\u001b[0;32m--> 335\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMlflowClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/mlflow/tracking/client.py\u001b[0m in \u001b[0;36mcreate_experiment\u001b[0;34m(self, name, artifact_location)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInteger\u001b[0m \u001b[0mID\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \"\"\"\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracking_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client.py\u001b[0m in \u001b[0;36mcreate_experiment\u001b[0;34m(self, name, artifact_location)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return self.store.create_experiment(\n\u001b[1;32m    125\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0martifact_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         )\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\u001b[0m in \u001b[0;36mcreate_experiment\u001b[0;34m(self, name, artifact_location)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 raise MlflowException(\"Experiment '%s' already exists.\" % experiment.name,\n\u001b[0;32m--> 230\u001b[0;31m                                       databricks_pb2.RESOURCE_ALREADY_EXISTS)\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;31m# Get all existing experiments and find the one with largest ID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;31m# len(list_all(..)) would not work when experiments are deleted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMlflowException\u001b[0m: Experiment 'gamma_log_facies_type_xgboost_cls_hyperopt' already exists."
     ]
    }
   ],
   "source": [
    "\n",
    "EXPERIMENT_ID = mlflow.create_experiment(\"gamma_log_facies_type_xgboost_cls_hyperopt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperoptHPOptimizer:\n",
    "    \n",
    "    def __init__(self, hyperparameters_space, max_evals):\n",
    "        self.trials = Trials()\n",
    "        self.max_evals = max_evals\n",
    "        self.hyperparameters_space = hyperparameters_space\n",
    "        self.skf = StratifiedKFold(n_splits=3, shuffle=False, random_state=RANDOM_STATE)\n",
    "    \n",
    "    def get_loss(self, hyperparameters):\n",
    "        # MLflow will track and save hyperparameters, loss, and scores. \n",
    "        with mlflow.start_run(\"\", experiment_id=EXPERIMENT_ID):\n",
    "            print(\"Training with the following hyperparameters: \")\n",
    "            print(hyperparameters)\n",
    "            for k, v in hyperparameters.items():\n",
    "                mlflow.log_param(k, v)\n",
    "            model = xgb.XGBClassifier(**hyperparameters)\n",
    "            \n",
    "            loss = cross_val_score(model, X, y, cv=self.skf, scoring=\"accuracy\", n_jobs=-1).mean()\n",
    "            # Log the various losses and metrics (on train and validation)\n",
    "            mlflow.log_metric(\"accuracy\", loss)\n",
    "            # Use the last validation loss from the history object to optimize\n",
    "            return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        This is the optimization function that given a space of \n",
    "        hyperparameters and a scoring function, finds the best hyperparameters.\n",
    "        \"\"\"\n",
    "        # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "        # Here we use the tree-parzen estimator method. \n",
    "        best = fmin(self.get_loss, self.hyperparameters_space, algo=tpe.suggest, \n",
    "                    trials=self.trials,  max_evals=self.max_evals)\n",
    "        return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with the following hyperparameters:         \n",
      "{'colsample_bytree': 0.6, 'eta': 0.225, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 1, 'n_estimators': 50, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "  0%|          | 0/150 [05:13<?, ?it/s, best loss: ?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-d6d470a01f32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mhp_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperoptHPOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHYPERPARAMETERS_SPACE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EVALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0moptimal_hyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_hyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-1fdcb2d17eb8>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Here we use the tree-parzen estimator method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         best = fmin(self.get_loss, self.hyperparameters_space, algo=tpe.suggest, \n\u001b[0;32m---> 30\u001b[0;31m                     trials=self.trials,  max_evals=self.max_evals)\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-1fdcb2d17eb8>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(self, hyperparameters)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Log the various losses and metrics (on train and validation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MAX_EVALS = 150\n",
    "\n",
    "HYPERPARAMETERS_SPACE = {\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 10, dtype=int)),\n",
    "    'gamma': hp.choice('gamma', np.arange(0.5, 5)),\n",
    "    'subsample': hp.choice('subsample', [0.6, 0.8, 1.0]),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.6, 1.0)),\n",
    "    'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "    'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "    'random_state': RANDOM_STATE, \n",
    "    'verbosity': 1, \n",
    "    'n_jobs': -1, \n",
    "    'n_estimators': 50, \n",
    "    'learning_rate': 0.02, \n",
    "}\n",
    "\n",
    "hp_optimizer = HyperoptHPOptimizer(hyperparameters_space=HYPERPARAMETERS_SPACE, max_evals=MAX_EVALS)\n",
    "optimal_hyperparameters = hp_optimizer.optimize()\n",
    "print(optimal_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2155"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_EVALS = 150\n",
    "\n",
    "HYPERPARAMETERS_SPACE = {\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 10, dtype=int)),\n",
    "    'gamma': hp.choice('gamma', np.arange(0.5, 5)),\n",
    "    'subsample': hp.choice('subsample', [0.6, 0.8, 1.0]),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.6, 1.0)),\n",
    "    'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "    'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "    'random_state': RANDOM_STATE, \n",
    "    'verbosity': 1, \n",
    "    'n_jobs': -1, \n",
    "    'n_estimators': 50, \n",
    "    'learning_rate': 0.02, \n",
    "}\n",
    "\n",
    "hp_optimizer = HyperoptHPOptimizer(hyperparameters_space=HYPERPARAMETERS_SPACE, max_evals=MAX_EVALS)\n",
    "optimal_hyperparameters = hp_optimizer.optimize()\n",
    "print(optimal_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"\")\n",
    "EXPERIMENT_ID = mlflow.create_experiment(\"gamma_log_facies_type_xgboost_cls_hyperopt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with the following hyperparameters:         \n",
      "{'criterion': 'entropy', 'max_depth': 19, 'max_features': 2, 'n_estimators': 20}\n",
      "Training with the following hyperparameters:                                       \n",
      "{'criterion': 'entropy', 'max_depth': 4, 'max_features': 1, 'n_estimators': 20}    \n",
      "Training with the following hyperparameters:                                       \n",
      "{'criterion': 'gini', 'max_depth': 5, 'max_features': 1, 'n_estimators': 20}       \n",
      "Training with the following hyperparameters:                                       \n",
      "{'criterion': 'gini', 'max_depth': 4, 'max_features': 1, 'n_estimators': 20}       \n",
      "Training with the following hyperparameters:                                       \n",
      "{'criterion': 'entropy', 'max_depth': 2, 'max_features': 2, 'n_estimators': 20}    \n",
      "Training with the following hyperparameters:                                       \n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': 1, 'n_estimators': 20}\n",
      "Training with the following hyperparameters:                                    \n",
      "{'criterion': 'entropy', 'max_depth': 1, 'max_features': 2, 'n_estimators': 20} \n",
      "Training with the following hyperparameters:                                    \n",
      "{'criterion': 'entropy', 'max_depth': 13, 'max_features': 2, 'n_estimators': 20}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'criterion': 'entropy', 'max_depth': 6, 'max_features': 1, 'n_estimators': 20}  \n",
      "Training with the following hyperparameters:                                     \n",
      "{'criterion': 'gini', 'max_depth': 2, 'max_features': 1, 'n_estimators': 20}    \n",
      "Training with the following hyperparameters:                                     \n",
      "{'criterion': 'gini', 'max_depth': 18, 'max_features': 2, 'n_estimators': 20}    \n",
      "Training with the following hyperparameters:                                      \n",
      "{'criterion': 'entropy', 'max_depth': 9, 'max_features': 2, 'n_estimators': 20}   \n",
      "Training with the following hyperparameters:                                      \n",
      "{'criterion': 'entropy', 'max_depth': 12, 'max_features': 1, 'n_estimators': 20}  \n",
      "  8%|▊         | 12/150 [20:03<3:50:43, 100.32s/it, best loss: -0.654813638572258]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-373e13198bfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mhp_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperoptHPOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHYPERPARAMETERS_SPACE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EVALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0moptimal_hyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_hyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-373e13198bfa>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Here we use the tree-parzen estimator method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         best = fmin(self.get_loss, self.hyperparameters_space, algo=tpe.suggest, \n\u001b[0;32m---> 34\u001b[0;31m                     trials=self.trials,  max_evals=self.max_evals)\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-373e13198bfa>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(self, hyperparameters)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Log the various losses and metrics (on train and validation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"gamma_log_facies_type_RandomForestClassifier_hyperopt\")\n",
    "\n",
    "class HyperoptHPOptimizer:\n",
    "    \n",
    "    def __init__(self, hyperparameters_space, max_evals):\n",
    "        self.trials = Trials()\n",
    "        self.max_evals = max_evals\n",
    "        self.hyperparameters_space = hyperparameters_space\n",
    "        self.skf = StratifiedKFold(n_splits=3, shuffle=False, random_state=RANDOM_STATE)\n",
    "    \n",
    "    def get_loss(self, hyperparameters):\n",
    "        # MLflow will track and save hyperparameters, loss, and scores. \n",
    "        with mlflow.start_run(run_name='hyperopt_param'):\n",
    "            print(\"Training with the following hyperparameters: \")\n",
    "            print(hyperparameters)\n",
    "            for k, v in hyperparameters.items():\n",
    "                mlflow.log_param(k, v)\n",
    "            model = RandomForestClassifier(**hyperparameters)\n",
    "            \n",
    "            loss = cross_val_score(model, X, y, cv=self.skf, scoring=\"accuracy\", n_jobs=-1).mean()\n",
    "            # Log the various losses and metrics (on train and validation)\n",
    "            mlflow.log_metric(\"accuracy\", loss)\n",
    "            # Use the last validation loss from the history object to optimize\n",
    "            return {'loss': -loss, 'status': STATUS_OK}\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        This is the optimization function that given a space of \n",
    "        hyperparameters and a scoring function, finds the best hyperparameters.\n",
    "        \"\"\"\n",
    "        # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "        # Here we use the tree-parzen estimator method. \n",
    "        best = fmin(self.get_loss, self.hyperparameters_space, algo=tpe.suggest, \n",
    "                    trials=self.trials,  max_evals=self.max_evals)\n",
    "        return best\n",
    "    \n",
    "MAX_EVALS = 150\n",
    "\n",
    "HYPERPARAMETERS_SPACE = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,3)),\n",
    "    'n_estimators': 20,\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "}\n",
    "\n",
    "hp_optimizer = HyperoptHPOptimizer(hyperparameters_space=HYPERPARAMETERS_SPACE, max_evals=MAX_EVALS)\n",
    "optimal_hyperparameters = hp_optimizer.optimize()\n",
    "print(optimal_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with the following hyperparameters:         \n",
      "{'colsample_bytree': 0.6, 'eta': 0.47500000000000003, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.025, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.25, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 9, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.325, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 4, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.25, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.1, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 9, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.25, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.375, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.025, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 9, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.2, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.25, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.42500000000000004, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.07500000000000001, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.05, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 2, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.125, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 9, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.2, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.375, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.1, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.2, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.30000000000000004, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.4, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.5, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.47500000000000003, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.15000000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.15000000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.15000000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.15000000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 11, 'min_child_weight': 3, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.17500000000000002, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 4, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.30000000000000004, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 5, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.07500000000000001, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.15000000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.025, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.225, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.30000000000000004, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 11, 'min_child_weight': 5, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.125, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.17500000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.07500000000000001, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.47500000000000003, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 3, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.35000000000000003, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.45, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 4, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.275, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 8, 'min_child_weight': 9, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.225, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.05, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.35000000000000003, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 11, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.125, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 2, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.42500000000000004, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.275, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 5, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.1, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 9, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.225, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 1, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.17500000000000002, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.05, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.2, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.1, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.025, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 2, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.25, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 8, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.5, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 4, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.325, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 9, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.15000000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.4, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 11, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.125, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.17500000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 1, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.07500000000000001, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.2, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.225, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.05, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.275, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.2, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.2, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.15000000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.25, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.25, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.25, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 2, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.325, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.275, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 8, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.30000000000000004, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 5, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.225, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 9, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.325, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.35000000000000003, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.47500000000000003, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 11, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.17500000000000002, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.1, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.2, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.125, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 2, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.4, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.375, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.375, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 8, 'min_child_weight': 5, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.30000000000000004, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.30000000000000004, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 9, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.07500000000000001, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.17500000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 11, 'min_child_weight': 6, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.5, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.025, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.15000000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                         \n",
      "{'colsample_bytree': 0.6, 'eta': 0.15000000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                         \n",
      "{'colsample_bytree': 0.6, 'eta': 0.1, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                         \n",
      "{'colsample_bytree': 0.6, 'eta': 0.1, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                         \n",
      "{'colsample_bytree': 0.6, 'eta': 0.125, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                         \n",
      "{'colsample_bytree': 0.6, 'eta': 0.05, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                         \n",
      "{'colsample_bytree': 0.6, 'eta': 0.07500000000000001, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 8, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                         \n",
      "{'colsample_bytree': 0.6, 'eta': 0.125, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.1, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.025, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.05, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 11, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.15000000000000002, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.1, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.225, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 2, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.275, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.17500000000000002, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.45, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 9, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.125, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.325, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.35000000000000003, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.07500000000000001, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.15000000000000002, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.17500000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 2, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.225, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 4, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.2, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 11, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.275, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.35000000000000003, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 9, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.25, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 1, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.42500000000000004, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.4, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.2, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 3, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.45, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 2, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.125, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.15000000000000002, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 8, 'min_child_weight': 4, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.17500000000000002, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 5, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.025, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 9, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.25, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 6, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                          \n",
      "{'colsample_bytree': 0.6, 'eta': 0.05, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.275, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 11, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.30000000000000004, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.30000000000000004, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.375, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.225, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 5, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.325, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.325, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 9, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.42500000000000004, 'gamma': 2.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.325, 'gamma': 1.5, 'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.375, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 8, 'min_child_weight': 3, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.4, 'gamma': 3.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.8, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.07500000000000001, 'gamma': 0.5, 'learning_rate': 0.02, 'max_depth': 13, 'min_child_weight': 2, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.35000000000000003, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.30000000000000004, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 4, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1.0, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.35000000000000003, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 11, 'min_child_weight': 5, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.30000000000000004, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.325, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.25, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.25, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                        \n",
      "{'colsample_bytree': 0.6, 'eta': 0.325, 'gamma': 4.5, 'learning_rate': 0.02, 'max_depth': 12, 'min_child_weight': 7, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 0.6, 'verbosity': 1}\n",
      "100%|██████████| 150/150 [7:10:25<00:00, 172.17s/it, best loss: 0.33065517024185703]\n",
      "{'colsample_bytree': 0, 'eta': 0.15000000000000002, 'gamma': 4, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0}\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"gamma_log_facies_type_xgboost_cls_hyperopt_2\")\n",
    "\n",
    "class HyperoptHPOptimizer:\n",
    "    \n",
    "    def __init__(self, hyperparameters_space, max_evals):\n",
    "        self.trials = Trials()\n",
    "        self.max_evals = max_evals\n",
    "        self.hyperparameters_space = hyperparameters_space\n",
    "        self.skf = StratifiedKFold(n_splits=3, shuffle=False, random_state=RANDOM_STATE)\n",
    "    \n",
    "    def get_loss(self, hyperparameters):\n",
    "        # MLflow will track and save hyperparameters, loss, and scores. \n",
    "        with mlflow.start_run(run_name='hyperopt_param'):\n",
    "            print(\"Training with the following hyperparameters: \")\n",
    "            print(hyperparameters)\n",
    "            for k, v in hyperparameters.items():\n",
    "                mlflow.log_param(k, v)\n",
    "            model = xgb.XGBClassifier(**hyperparameters)\n",
    "            \n",
    "            loss = cross_val_score(model, X, y, cv=self.skf, scoring=\"accuracy\", n_jobs=-1).mean()\n",
    "            # Log the various losses and metrics (on train and validation)\n",
    "            mlflow.log_metric(\"accuracy\", loss)\n",
    "            # Use the last validation loss from the history object to optimize\n",
    "            return {'loss': -loss, 'status': STATUS_OK}\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        This is the optimization function that given a space of \n",
    "        hyperparameters and a scoring function, finds the best hyperparameters.\n",
    "        \"\"\"\n",
    "        # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "        # Here we use the tree-parzen estimator method. \n",
    "        best = fmin(self.get_loss, self.hyperparameters_space, algo=tpe.suggest, \n",
    "                    trials=self.trials,  max_evals=self.max_evals)\n",
    "        return best\n",
    "\n",
    "\n",
    "\n",
    "MAX_EVALS = 150\n",
    "\n",
    "HYPERPARAMETERS_SPACE = {\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 10, dtype=int)),\n",
    "    'gamma': hp.choice('gamma', np.arange(0.5, 5)),\n",
    "    'subsample': hp.choice('subsample', [0.6, 0.8, 1.0]),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.6, 1.0)),\n",
    "    'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "    'max_depth':  hp.choice('max_depth', np.arange(4, 14, dtype=int)),\n",
    "    'random_state': RANDOM_STATE, \n",
    "    'verbosity': 1, \n",
    "    'n_jobs': -1, \n",
    "    'n_estimators': 20, \n",
    "    'learning_rate': 0.02, \n",
    "}\n",
    "\n",
    "hp_optimizer = HyperoptHPOptimizer(hyperparameters_space=HYPERPARAMETERS_SPACE, max_evals=MAX_EVALS)\n",
    "optimal_hyperparameters = hp_optimizer.optimize()\n",
    "print(optimal_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with the following hyperparameters:         \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.02, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 882, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "  0%|          | 0/150 [16:55<?, ?it/s, best loss: ?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-a34da6235d92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mhp_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperoptHPOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHYPERPARAMETERS_SPACE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EVALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0moptimal_hyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_hyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-a34da6235d92>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Here we use the tree-parzen estimator method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         best = fmin(self.get_loss, self.hyperparameters_space, algo=tpe.suggest, \n\u001b[0;32m---> 34\u001b[0;31m                     trials=self.trials,  max_evals=self.max_evals)\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-a34da6235d92>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(self, hyperparameters)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Log the various losses and metrics (on train and validation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"gamma_log_facies_type_xgboost_cls_hyperopt_2\")\n",
    "\n",
    "class HyperoptHPOptimizer:\n",
    "    \n",
    "    def __init__(self, hyperparameters_space, max_evals):\n",
    "        self.trials = Trials()\n",
    "        self.max_evals = max_evals\n",
    "        self.hyperparameters_space = hyperparameters_space\n",
    "        self.skf = StratifiedKFold(n_splits=3, shuffle=False, random_state=RANDOM_STATE)\n",
    "    \n",
    "    def get_loss(self, hyperparameters):\n",
    "        # MLflow will track and save hyperparameters, loss, and scores. \n",
    "        with mlflow.start_run(run_name='hyperopt_param'):\n",
    "            print(\"Training with the following hyperparameters: \")\n",
    "            print(hyperparameters)\n",
    "            for k, v in hyperparameters.items():\n",
    "                mlflow.log_param(k, v)\n",
    "            model = xgb.XGBClassifier(**hyperparameters)\n",
    "            \n",
    "            loss = cross_val_score(model, X, y, cv=self.skf, scoring=\"accuracy\", n_jobs=-1).mean()\n",
    "            # Log the various losses and metrics (on train and validation)\n",
    "            mlflow.log_metric(\"accuracy\", loss)\n",
    "            # Use the last validation loss from the history object to optimize\n",
    "            return {'loss': -loss, 'status': STATUS_OK}\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        This is the optimization function that given a space of \n",
    "        hyperparameters and a scoring function, finds the best hyperparameters.\n",
    "        \"\"\"\n",
    "        # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "        # Here we use the tree-parzen estimator method. \n",
    "        best = fmin(self.get_loss, self.hyperparameters_space, algo=tpe.suggest, \n",
    "                    trials=self.trials,  max_evals=self.max_evals)\n",
    "        return best\n",
    "\n",
    "\n",
    "\n",
    "MAX_EVALS = 150\n",
    "\n",
    "HYPERPARAMETERS_SPACE = {\n",
    "    'min_child_weight': 8,\n",
    "    'gamma': 3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'eta': 0.3,\n",
    "    'max_depth':  4,\n",
    "    'random_state': RANDOM_STATE, \n",
    "    'verbosity': 1, \n",
    "    'n_jobs': -1, \n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(1, 1000, dtype=int)), \n",
    "    'learning_rate': 0.02, \n",
    "}\n",
    "\n",
    "hp_optimizer = HyperoptHPOptimizer(hyperparameters_space=HYPERPARAMETERS_SPACE, max_evals=MAX_EVALS)\n",
    "optimal_hyperparameters = hp_optimizer.optimize()\n",
    "print(optimal_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with the following hyperparameters:         \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.0027891246529111475, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.011680282622024111, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.0006893413851240221, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 4.239419052738074e-06, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.006035095027057003, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 1.189850389621798e-05, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 6.385290166610366e-05, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.01462647020529976, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.0023452879909156748, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                      \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 7.370636398542982e-05, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                       \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.0665532271921076, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                       \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 4.925596779666195e-06, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                       \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.0008374653909279349, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                       \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 1.2679006016337461e-05, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                       \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.0008228991304768916, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                       \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.0012612608957767977, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                       \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.00010547340245511237, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                       \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.013914227282153637, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                       \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 5.0430906969829734e-05, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      " 12%|█▏        | 18/150 [34:16<4:11:22, 114.26s/it, best loss: -0.5970506971823604]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-23f61877e5c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mhp_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperoptHPOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHYPERPARAMETERS_SPACE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EVALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0moptimal_hyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_hyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-23f61877e5c0>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Here we use the tree-parzen estimator method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         best = fmin(self.get_loss, self.hyperparameters_space, algo=tpe.suggest, \n\u001b[0;32m---> 34\u001b[0;31m                     trials=self.trials,  max_evals=self.max_evals)\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-23f61877e5c0>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(self, hyperparameters)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Log the various losses and metrics (on train and validation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 232\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"gamma_log_facies_type_xgboost_cls_hyperopt_2\")\n",
    "\n",
    "class HyperoptHPOptimizer:\n",
    "    \n",
    "    def __init__(self, hyperparameters_space, max_evals):\n",
    "        self.trials = Trials()\n",
    "        self.max_evals = max_evals\n",
    "        self.hyperparameters_space = hyperparameters_space\n",
    "        self.skf = StratifiedKFold(n_splits=3, shuffle=False, random_state=RANDOM_STATE)\n",
    "    \n",
    "    def get_loss(self, hyperparameters):\n",
    "        # MLflow will track and save hyperparameters, loss, and scores. \n",
    "        with mlflow.start_run(run_name='hyperopt_param'):\n",
    "            print(\"Training with the following hyperparameters: \")\n",
    "            print(hyperparameters)\n",
    "            for k, v in hyperparameters.items():\n",
    "                mlflow.log_param(k, v)\n",
    "            model = xgb.XGBClassifier(**hyperparameters)\n",
    "            \n",
    "            loss = cross_val_score(model, X, y, cv=self.skf, scoring=\"accuracy\", n_jobs=-1).mean()\n",
    "            # Log the various losses and metrics (on train and validation)\n",
    "            mlflow.log_metric(\"accuracy\", loss)\n",
    "            # Use the last validation loss from the history object to optimize\n",
    "            return {'loss': -loss, 'status': STATUS_OK}\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        This is the optimization function that given a space of \n",
    "        hyperparameters and a scoring function, finds the best hyperparameters.\n",
    "        \"\"\"\n",
    "        # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "        # Here we use the tree-parzen estimator method. \n",
    "        best = fmin(self.get_loss, self.hyperparameters_space, algo=tpe.suggest, \n",
    "                    trials=self.trials,  max_evals=self.max_evals)\n",
    "        return best\n",
    "\n",
    "\n",
    "\n",
    "MAX_EVALS = 150\n",
    "\n",
    "HYPERPARAMETERS_SPACE = {\n",
    "    'min_child_weight': 8,\n",
    "    'gamma': 3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'eta': 0.3,\n",
    "    'max_depth':  4,\n",
    "    'random_state': RANDOM_STATE, \n",
    "    'verbosity': 1, \n",
    "    'n_jobs': -1, \n",
    "    'n_estimators': 20, \n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.000001), np.log(0.1)), \n",
    "}\n",
    "\n",
    "hp_optimizer = HyperoptHPOptimizer(hyperparameters_space=HYPERPARAMETERS_SPACE, max_evals=MAX_EVALS)\n",
    "optimal_hyperparameters = hp_optimizer.optimize()\n",
    "print(optimal_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1320000, 3), (1320000,))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_subset = X[:int(X.shape[0]*0.3)]\n",
    "y_subset = y[:X_subset.shape[0]]\n",
    "X_subset.shape, y_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with the following hyperparameters:         \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.7871441954964349, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.3239432396973265, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.3298180880334005, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.41007259690082976, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.459277137958891, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.5469886158234346, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.8632289107774737, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "Training with the following hyperparameters:                                     \n",
      "{'colsample_bytree': 0.6, 'eta': 0.3, 'gamma': 3, 'learning_rate': 0.7377502490269473, 'max_depth': 4, 'min_child_weight': 8, 'n_estimators': 20, 'n_jobs': -1, 'random_state': 42, 'subsample': 1, 'verbosity': 1}\n",
      "  5%|▍         | 7/150 [04:43<1:36:26, 40.47s/it, best loss: -0.6651098484848484]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-a8bd28e81109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mhp_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperoptHPOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHYPERPARAMETERS_SPACE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EVALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0moptimal_hyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_hyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-a8bd28e81109>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Here we use the tree-parzen estimator method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         best = fmin(self.get_loss, self.hyperparameters_space, algo=tpe.suggest, \n\u001b[0;32m---> 40\u001b[0;31m                     trials=self.trials,  max_evals=self.max_evals)\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         )\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[1;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[1;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 856\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-a8bd28e81109>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(self, hyperparameters)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/cv_projects/venv/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"gamma_log_facies_type_xgboost_cls_hyperopt_subset\")\n",
    "\n",
    "class HyperoptHPOptimizer:\n",
    "    \n",
    "    def __init__(self, hyperparameters_space, max_evals):\n",
    "        self.trials = Trials()\n",
    "        self.max_evals = max_evals\n",
    "        self.hyperparameters_space = hyperparameters_space\n",
    "        self.skf = StratifiedKFold(n_splits=3, shuffle=False, random_state=RANDOM_STATE)\n",
    "    \n",
    "    def get_loss(self, hyperparameters):\n",
    "        # MLflow will track and save hyperparameters, loss, and scores. \n",
    "        with mlflow.start_run(run_name='hyperopt_param'):\n",
    "            print(\"Training with the following hyperparameters: \")\n",
    "            print(hyperparameters)\n",
    "            for k, v in hyperparameters.items():\n",
    "                mlflow.log_param(k, v)\n",
    "            model = xgb.XGBClassifier(**hyperparameters)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.2, random_state=RANDOM_STATE, stratify=y_subset)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            loss = accuracy_score(y_test, y_pred)\n",
    "            # Log the various losses and metrics (on train and validation)\n",
    "            mlflow.log_metric(\"accuracy\", loss)\n",
    "            # Use the last validation loss from the history object to optimize\n",
    "            return {\n",
    "                'loss': -loss, \n",
    "                'status': STATUS_OK,\n",
    "                'eval_time': time()\n",
    "            }\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        This is the optimization function that given a space of \n",
    "        hyperparameters and a scoring function, finds the best hyperparameters.\n",
    "        \"\"\"\n",
    "        # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "        # Here we use the tree-parzen estimator method. \n",
    "        best = fmin(self.get_loss, self.hyperparameters_space, algo=tpe.suggest, \n",
    "                    trials=self.trials,  max_evals=self.max_evals)\n",
    "        return best\n",
    "\n",
    "\n",
    "\n",
    "MAX_EVALS = 150\n",
    "\n",
    "HYPERPARAMETERS_SPACE = {\n",
    "    'min_child_weight': 8,\n",
    "    'gamma': 3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'eta': 0.3,\n",
    "    'max_depth':  4,\n",
    "    'random_state': RANDOM_STATE, \n",
    "    'verbosity': 1, \n",
    "    'n_jobs': -1, \n",
    "    'n_estimators': 20, \n",
    "    'learning_rate': hp.uniform('learning_rate', 0.1, 0.9), \n",
    "}\n",
    "\n",
    "hp_optimizer = HyperoptHPOptimizer(hyperparameters_space=HYPERPARAMETERS_SPACE, max_evals=MAX_EVALS)\n",
    "optimal_hyperparameters = hp_optimizer.optimize()\n",
    "print(optimal_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'min_child_weight': 8,\n",
    "    'gamma': 3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'eta': 0.3,\n",
    "    'max_depth':  4,\n",
    "    'random_state': RANDOM_STATE, \n",
    "    'verbosity': 1, \n",
    "    'n_jobs': -1, \n",
    "    'n_estimators': 500, \n",
    "    'learning_rate': 0.1, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:34] WARNING: src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "CPU times: user 1h 7min 55s, sys: 26.9 s, total: 1h 8min 22s\n",
      "Wall time: 1h 9min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6, eta=0.3, gamma=3,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=8, missing=None, n_estimators=500, n_jobs=-1,\n",
       "              nthread=None, objective='multi:softprob', random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = xgb.XGBClassifier(**hyperparameters)\n",
    "X, y = train_df.drop(\"label\", axis=1), train_df[\"label\"]\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 42s, sys: 1.07 s, total: 2min 43s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_hat = model.predict(test_df[[\"row_id\", \"well_id\", \"GR\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAX_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAX_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAX_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAX_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAX_4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CAX_5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAX_6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CAX_7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CAX_8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CAX_9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CAX_10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CAX_11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CAX_12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAX_13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CAX_14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CAX_15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CAX_16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CAX_17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CAX_18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CAX_19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_id  label\n",
       "0      CAX_0      0\n",
       "1      CAX_1      0\n",
       "2      CAX_2      0\n",
       "3      CAX_3      0\n",
       "4      CAX_4      0\n",
       "5      CAX_5      0\n",
       "6      CAX_6      0\n",
       "7      CAX_7      0\n",
       "8      CAX_8      0\n",
       "9      CAX_9      0\n",
       "10    CAX_10      0\n",
       "11    CAX_11      0\n",
       "12    CAX_12      0\n",
       "13    CAX_13      0\n",
       "14    CAX_14      0\n",
       "15    CAX_15      0\n",
       "16    CAX_16      0\n",
       "17    CAX_17      0\n",
       "18    CAX_18      2\n",
       "19    CAX_19      2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_df[\"label\"] = y_hat\n",
    "submit_df.to_csv(root+\"submission.csv\", index=False)\n",
    "submit_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Количество классов для предсказания\n",
    "\n",
    "g = submit_df[\"label\"].value_counts()\n",
    "g = g.sort_index().T\n",
    "plt.bar(g.index, g.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/Gamma_Log_Facies_Type_Prediction/gamma_log_facies_type_xgboost_cls_hyperopt_subset.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = models_root + \"gamma_log_facies_type_xgboost_cls_hyperopt_subset.pkl\"\n",
    "dump(model, model_file)\n",
    "# loaded_model = load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
